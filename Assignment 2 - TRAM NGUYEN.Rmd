---
title: "Assignment 2"
output:
  pdf_document: default
  html_document: default
date: "2023-09-28"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
#Summary

## Questions - Answers

1. This new customer would be classified as 0, does not take the personal loan
2. The best K is 3
3. The confusion matrix of validation has TN = 1786, TP = 142, FN = 63, FP = 9
4. With k=3, the customer is classified as 0, means that he/she declines the loan.
5. Compare the three confusion matrix we can see the Specificity rate of three data sets giving nearly the same percentage at 99,78%, which can correctly identify the true decline customer cases. Beside that, the training set has the highest sensitivity rate among other data sets. So it should be said that, training set is the more reliable data. 

#General steps
```{r}
#Step 1: Loading the Libraries.
library(class)
library(caret)
library(e1071)

#Step 2: Read the csv file.
universal.df <- read.csv("C:/Users/ADMIN/Downloads/UniversalBank.csv")
dim(universal.df)
t(t(names(universal.df)))

#Step 3: Drop ID and ZIP variables.
universal.df <- universal.df[,-c(1,5)]

#Step 4: Transforming the categorical variables into dummy variables.
universal.df$Education <- as.factor(universal.df$Education)
groups <- dummyVars(~., data = universal.df) 
universal_m.df <- as.data.frame(predict(groups,universal.df))
```
```{r}
#Step 5: Splitting the Data into 60% training and 40% validation set. 
set.seed(1) 
train.index <- sample(row.names(universal_m.df), 0.6*dim(universal_m.df)[1])
valid.index <- setdiff(row.names(universal_m.df), train.index)  
train.df <- universal_m.df[train.index,]
valid.df <- universal_m.df[valid.index,]
t(t(names(train.df)))

#Step 6: Normalizing the data.
train.norm.df <- train.df[,-10] 
valid.norm.df <- valid.df[,-10]

norm.values <- preProcess(train.df[, -10], method=c("center", "scale"))
train.norm.df <- predict(norm.values, train.df[, -10])
valid.norm.df <- predict(norm.values, valid.df[, -10])
```

#Question:
Consider the following customer:

1.Age = 40, Experience = 10, Income = 84, Family = 2, CCAvg = 2, Education_1 = 0, Education_2 = 1, Education_3 = 0, Mortgage = 0, Securities Account = 0, CD Account = 0, Online = 1, and Credit Card = 1. Perform a k-NN classification with all predictors except ID and ZIP code using k = 1. Remember to transform categorical predictors with more than two categories into dummy variables first. Specify the success class as 1 (loan acceptance), and use the default cutoff value of 0.5. How would this customer be classified?
```{r}
new_customer <- data.frame(
  Age = 40,
  Experience = 10,
  Income = 84,
  Family = 2,
  CCAvg = 2,
  Education.1 = 0,
  Education.2 = 1,
  Education.3 = 0,
  Mortgage = 0,
  Securities.Account = 0,
  CD.Account = 0,
  Online = 1,
  CreditCard = 1
)
# Normalize the new customer
new.cust.norm <- new_customer
new.cust.norm <- predict(norm.values, new.cust.norm)

#Predicting whether the new customer will accept or decline the loan using kNN as k=1.
knn.pred <- class::knn(train = train.norm.df, 
                       test = new.cust.norm, 
                       cl = train.df$Personal.Loan, k = 1)
knn.pred
```

2.What is a choice of k that balances between overfitting and ignoring the predictor
information?

```{r}
# Calculate the accuracy for each value of k, set the range of k values to consider
accuracy.df <- data.frame(k = seq(1, 15, 1), overallaccuracy = rep(0, 15))
for(i in 1:15) {
  knn.pred <- class::knn(train = train.norm.df, 
                         test = valid.norm.df, 
                         cl = train.df$Personal.Loan, k = i)
  accuracy.df[i, 2] <- confusionMatrix(knn.pred, 
                                       as.factor(valid.df$Personal.Loan),positive = "1")$overall[1]
}
best_k <- accuracy.df[which.max(accuracy.df$overallaccuracy), "k"]
print(best_k)

which(accuracy.df[,2] == max(accuracy.df[,2])) 

plot(accuracy.df$k,accuracy.df$overallaccuracy)
```

3.Show the confusion matrix for the validation data that results from using the best k.

```{r}

    knn.pred <- class::knn(train = train.norm.df, 
                            test = valid.norm.df, 
                            cl = train.df$Personal.Loan, k = 3)
    confusion_matrix <- confusionMatrix(knn.pred, 
                            as.factor(valid.df$Personal.Loan), positive = "1")

print(confusion_matrix)

```

4.Consider the following customer: Age = 40, Experience = 10, Income = 84, Family = 2, CCAvg = 2, Education_1 = 0, Education_2 = 1, Education_3 = 0, Mortgage = 0, Securities Account = 0, CD Account = 0, Online = 1 and Credit Card = 1. Classify the customer using the best k.
```{r}
new_customer <- data.frame(
  Age = 40,
  Experience = 10,
  Income = 84,
  Family = 2,
  CCAvg = 2,
  Education.1 = 0,
  Education.2 = 1,
  Education.3 = 0,
  Mortgage = 0,
  Securities.Account = 0,
  CD.Account = 0,
  Online = 1,
  CreditCard = 1
)

# Normalize the new customer
new.cust.norm <- new_customer
new.cust.norm <- predict(norm.values, new.cust.norm)

#Predicting whether the new customer will accept or decline the loan using kNN as k= 3. 
knn.pred <- class::knn(train = train.norm.df, 
                       test = new.cust.norm, 
                       cl = train.df$Personal.Loan, k = 3)
knn.pred

```


5.Repartition the data, this time into training, validation, and test sets (50% : 30% : 20%). Apply
the k-NN method with the k chosen above. Compare the confusion matrix of the test set
with that of the training and validation sets. Comment on the differences and their reason.

```{r}
#Partition the data into training (50%), validation (30%) and Test set (20%)
set.seed(1) 
train.index <- sample(row.names(universal_m.df), 0.5*dim(universal_m.df)[1])
valid.index <- sample(row.names(universal_m.df), 0.3*dim(universal_m.df)[1])
test_set.index <- sample(row.names(universal_m.df), 0.2*dim(universal_m.df)[1])
train.df <- universal_m.df[train.index,]
valid.df <- universal_m.df[valid.index,]
test.df<- universal_m.df[test_set.index,]

print(paste("The size of the training set is:", nrow(train.df)))
print(paste("The size of the validation set is:", nrow(valid.df)))
print(paste("The size of the validation set is:", nrow(test.df)))

#Normalizing the data.
train.norm.df <- train.df[,-10]
valid.norm.df <- valid.df[,-10]
test.norm.df <- test.df [,-10]

norm.values <- preProcess(train.df[, -10], method=c("center", "scale"))
train.norm.df <- predict(norm.values, train.df[, -10])
valid.norm.df <- predict(norm.values, valid.df[, -10])
test.norm.df <- predict (norm.values, test.df [,-10])

#Create confusion matrix and Statistics for each data set

#Confusion matrix for test set
  knn.pred <- class::knn(train = train.norm.df, 
                         test = test.norm.df,
                         cl = train.df$Personal.Loan, k = 3)
    conf_matrix_test <- confusionMatrix(knn.pred, 
                                as.factor(test.df$Personal.Loan), positive = "1")
    print(conf_matrix_test)
    
#Confusion matrix for training set  
  knn.pred <- class::knn(train = train.norm.df, 
                            test = train.norm.df, 
                            cl = train.df$Personal.Loan, k = 3)
    conf_matrix_train <- confusionMatrix(knn.pred, 
                                as.factor(train.df$Personal.Loan), positive = "1")
    print(conf_matrix_train)
    
#Confusion matrix for valid set
  knn.pred <- class::knn(train = train.norm.df,
                         test = valid.norm.df,
                         cl = train.df$Personal.Loan, k = 3) 
    conf_matrix_valid <- confusionMatrix(knn.pred, 
                                as.factor(valid.df$Personal.Loan), positive = "1")
    print(conf_matrix_valid)
  
```
